{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7011378",
   "metadata": {},
   "source": [
    "NLP Project for KU Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ecaf78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## Load the dataset\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4c03e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unwanted characters from the questions\n",
    "\n",
    "def cleanDf(df):\n",
    "    \n",
    "    pattern = re.compile(r\"[?؟,;\\/\\\\\\[\\]#():]\")\n",
    "    df['question'] = df['question'].apply(lambda x: pattern.sub(\"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "feffa14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Train Questions: 2558, Validation Questions: 415\n",
      "Language: ar, Train Total Words: 16202, Validation Total Words: 2621\n",
      "Language: ko, Train Questions: 2422, Validation Questions: 356\n",
      "Language: ko, Train Total Words: 11840, Validation Total Words: 1729\n",
      "Language: te, Train Questions: 1355, Validation Questions: 384\n",
      "Language: te, Train Total Words: 7668, Validation Total Words: 2299\n"
     ]
    }
   ],
   "source": [
    "langForStat = ['ar','ko','te']\n",
    "\n",
    "numQuestions = []\n",
    "totalWordCount = []\n",
    "distinctWordCount = []\n",
    "distinctCharCount = []\n",
    "\n",
    "df_train_clean = cleanDf(df_train)\n",
    "df_val_clean = cleanDf(df_val)\n",
    "\n",
    "for lang in langForStat:\n",
    "    numQuestions_train = df_train_clean[df_train_clean['lang'] == lang].shape[0]\n",
    "    numQuestions_val = df_val_clean[df_val_clean['lang'] == lang].shape[0]\n",
    "    numQuestions.append((lang, numQuestions_train, numQuestions_val))\n",
    "    print(f\"Language: {lang}, Train Questions: {numQuestions_train}, Validation Questions: {numQuestions_val}\")\n",
    "\n",
    "    # Compute word and character statistics\n",
    "    df_train_lang = df_train_clean[df_train_clean['lang'] == lang].copy()\n",
    "    df_val_lang = df_val_clean[df_val_clean['lang'] == lang]\n",
    "    df_train_lang['wordcount'] = df_train_lang['question'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "\n",
    "    maxId = df_train_lang['wordcount'].idxmax()\n",
    "    longest_question = df_train_lang.loc[maxId, \"question\"]\n",
    "    max_words = df_train_lang.loc[maxId, \"wordcount\"]\n",
    "\n",
    "    # print(f\"Language: {lang}\")\n",
    "    # print(f\"  Longest train question (index {maxId}): {longest_question}\")\n",
    "    # print(f\"  Word count: {max_words}\")\n",
    "\n",
    "    totalWordCount_train = df_train_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount_val = df_val_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount.append((lang, totalWordCount_train, totalWordCount_val))\n",
    "    print(f\"Language: {lang}, Train Total Words: {totalWordCount_train}, Validation Total Words: {totalWordCount_val}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "74be8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Distinct Words: 5427\n",
      "Language: ar, Distinct Characters: 106\n",
      "Language: ar, Calculated Total Words from Distinct Words: 16202\n",
      "Language: ar, Top 5 Words: [('في', 592), ('من', 584), ('متى', 535), ('ما', 441), ('هو', 349), ('هل', 329), ('هي', 268), ('كم', 256), ('عدد', 161), ('أول', 157)]\n",
      "Language: ko, Distinct Words: 4394\n",
      "Language: ko, Distinct Characters: 819\n",
      "Language: ko, Calculated Total Words from Distinct Words: 11840\n",
      "Language: ko, Top 5 Words: [('가장', 527), ('무엇인가', 497), ('언제', 336), ('몇', 234), ('어디인가', 228), ('큰', 194), ('누구인가', 186), ('세상에서', 142), ('누구인가요', 105), ('무엇인가요', 95)]\n",
      "Language: te, Distinct Words: 2420\n",
      "Language: te, Distinct Characters: 91\n",
      "Language: te, Calculated Total Words from Distinct Words: 7668\n",
      "Language: te, Top 5 Words: [('ఎవరు', 274), ('ఏది', 192), ('ఎన్ని', 165), ('ఎప్పుడు', 154), ('ఏ', 142), ('ఎంత', 116), ('చిత్ర', 97), ('ఎక్కడ', 96), ('మొదటి', 86), ('ఉంది', 83)]\n"
     ]
    }
   ],
   "source": [
    "# from googletrans import Translator\n",
    "\n",
    "def wordCount(df, lang):\n",
    "    allWords = []\n",
    "    df = df[df['lang'] == lang].copy()\n",
    "    \n",
    "    # df = df[df['answerable'] == False]\n",
    "    df['question'] = df['question'].astype(str)\n",
    "\n",
    "    for q in df['question']:\n",
    "        allWords.extend(q.split()) \n",
    "    \n",
    "    wordDict = dict(Counter(allWords))\n",
    "    wordDict = dict(sorted(wordDict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return wordDict\n",
    "            \n",
    "\n",
    "for lang in langForStat:\n",
    "    wordDict = wordCount(df_train_clean, lang)\n",
    "    distinctWordCount.append((lang, len(wordDict)))\n",
    "    print(f\"Language: {lang}, Distinct Words: {len(wordDict)}\")\n",
    "\n",
    "    allChars = []\n",
    "    for word in wordDict.keys():\n",
    "        allChars.extend(list(word))\n",
    "    \n",
    "    charDict = dict(Counter(allChars))\n",
    "    charDict = dict(sorted(charDict.items(), key=lambda item: item[1], reverse=True))\n",
    "    distinctCharCount.append((lang, len(charDict)))\n",
    "    print(f\"Language: {lang}, Distinct Characters: {len(charDict)}\")\n",
    "    calculatedTotalWords = sum(wordDict.values())\n",
    "    print(f\"Language: {lang}, Calculated Total Words from Distinct Words: {calculatedTotalWords}\")\n",
    "\n",
    "    top5Words = list(wordDict.items())[:10]\n",
    "    print(f\"Language: {lang}, Top 5 Words: {top5Words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "976793c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Classifier Accuracy (validation): 96.87%\n",
      "True distribution in validation set: {True: 0.8746987951807229, False: 0.12530120481927712}\n",
      "Korean Classifier Accuracy (validation): 94.94%\n",
      "True distribution in validation set: {True: 0.9466292134831461, False: 0.05337078651685393}\n",
      "Telugu Classifier Accuracy (validation): 79.17%\n",
      "True distribution in validation set: {True: 0.7578125, False: 0.2421875}\n"
     ]
    }
   ],
   "source": [
    "def arabicClassifier(question, context):\n",
    "    goodWords = ['متى','ما','هو','هي','كم','عدد','أول','في']\n",
    "    badWords = ['هل', 'يمكن']\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "def koreanClassifier(question, context):\n",
    "    goodWords = ['가장', '무엇인가', '언제', '몇']\n",
    "    badWords = ['수 '] # '시차는', '중력과'\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "    \n",
    "def teluguClassifier(question, context):\n",
    "    goodWords = []\n",
    "    badWords = ['విస్తీర్ణం', 'జనాభా', 'ఆఫ్రికాలో']\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "            return True\n",
    "    # if any(word in question for word in badWords):\n",
    "    #     return False\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "### --- Arabic ---\n",
    "arabicDf = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "arabicDf['prediction'] = arabicDf.apply(lambda row: arabicClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (arabicDf['answerable'] == arabicDf['prediction']).mean()\n",
    "print(f\"Arabic Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {arabicDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Korean ---\n",
    "koreanDf = df_val_clean[df_val_clean['lang'] == 'ko'].copy()\n",
    "koreanDf['prediction'] = koreanDf.apply(lambda row: koreanClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (koreanDf['answerable'] == koreanDf['prediction']).mean()\n",
    "print(f\"Korean Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {koreanDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Telugu ---\n",
    "teluguDf = df_val_clean[df_val_clean['lang'] == 'te'].copy()\n",
    "teluguDf['prediction'] = teluguDf.apply(lambda row: teluguClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (teluguDf['answerable'] == teluguDf['prediction']).mean()\n",
    "print(f\"Telugu Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {teluguDf['answerable'].value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e06111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Classifier Accuracy (validation): 96.87%\n"
     ]
    }
   ],
   "source": [
    "def overlap_ratio(question, context):\n",
    "    q_words = set(question.split())\n",
    "    c_words = set(context.split())\n",
    "    if not q_words: return 0\n",
    "    return len(q_words & c_words) / len(q_words)\n",
    "\n",
    "\n",
    "import re\n",
    "def contains_digit(text):\n",
    "    return bool(re.search(r\"\\d+\", text))\n",
    "\n",
    "\n",
    "def arabicClassifier(question, context):\n",
    "    goodWords = ['متى','ما','هو','هي','كم','عدد','أول','في']\n",
    "    badWords = ['هل', 'يمكن']\n",
    "    \n",
    "    # Rule 1: keyword spotting\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    \n",
    "    # Rule 2: overlap\n",
    "    if overlap_ratio(question, context) < 0.1:\n",
    "        return False\n",
    "    \n",
    "    # # Rule 3: digits\n",
    "    # if contains_digit(question) and not contains_digit(context):\n",
    "    #     return False\n",
    "    \n",
    "    # # Rule 4: context length\n",
    "    # if len(context.split()) < 30:\n",
    "    #     return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Arabic\n",
    "arabicDf = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "arabicDf['prediction'] = arabicDf.apply(lambda row: arabicClassifier(row['question'], row['context']), axis=1)\n",
    "arabic_acc = (arabicDf['answerable'] == arabicDf['prediction']).mean()\n",
    "print(f\"Arabic Classifier Accuracy (validation): {arabic_acc*100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a39729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
