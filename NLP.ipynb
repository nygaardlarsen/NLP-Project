{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7011378",
   "metadata": {},
   "source": [
    "NLP Project for KU Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ecaf78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## Load the dataset\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c03e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unwanted characters from the questions\n",
    "\n",
    "def cleanDf(df):\n",
    "    \n",
    "    pattern = re.compile(r\"[?؟,;\\/\\\\\\[\\]#():]\")\n",
    "    df['question'] = df['question'].apply(lambda x: pattern.sub(\"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "feffa14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Train Questions: 2558, Validation Questions: 415\n",
      "Language: ar, Train Total Words: 16202, Validation Total Words: 2621\n",
      "Language: ko, Train Questions: 2422, Validation Questions: 356\n",
      "Language: ko, Train Total Words: 11840, Validation Total Words: 1729\n",
      "Language: te, Train Questions: 1355, Validation Questions: 384\n",
      "Language: te, Train Total Words: 7668, Validation Total Words: 2299\n"
     ]
    }
   ],
   "source": [
    "langForStat = ['ar','ko','te']\n",
    "\n",
    "numQuestions = []\n",
    "totalWordCount = []\n",
    "distinctWordCount = []\n",
    "distinctCharCount = []\n",
    "\n",
    "df_train_clean = cleanDf(df_train)\n",
    "df_val_clean = cleanDf(df_val)\n",
    "\n",
    "for lang in langForStat:\n",
    "    numQuestions_train = df_train_clean[df_train_clean['lang'] == lang].shape[0]\n",
    "    numQuestions_val = df_val_clean[df_val_clean['lang'] == lang].shape[0]\n",
    "    numQuestions.append((lang, numQuestions_train, numQuestions_val))\n",
    "    print(f\"Language: {lang}, Train Questions: {numQuestions_train}, Validation Questions: {numQuestions_val}\")\n",
    "\n",
    "    # Compute word and character statistics\n",
    "    df_train_lang = df_train_clean[df_train_clean['lang'] == lang].copy()\n",
    "    df_val_lang = df_val_clean[df_val_clean['lang'] == lang]\n",
    "    df_train_lang['wordcount'] = df_train_lang['question'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "\n",
    "    maxId = df_train_lang['wordcount'].idxmax()\n",
    "    longest_question = df_train_lang.loc[maxId, \"question\"]\n",
    "    max_words = df_train_lang.loc[maxId, \"wordcount\"]\n",
    "\n",
    "    # print(f\"Language: {lang}\")\n",
    "    # print(f\"  Longest train question (index {maxId}): {longest_question}\")\n",
    "    # print(f\"  Word count: {max_words}\")\n",
    "\n",
    "    totalWordCount_train = df_train_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount_val = df_val_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount.append((lang, totalWordCount_train, totalWordCount_val))\n",
    "    print(f\"Language: {lang}, Train Total Words: {totalWordCount_train}, Validation Total Words: {totalWordCount_val}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74be8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Distinct Words: 240\n",
      "Language: ar, Distinct Characters: 40\n",
      "Language: ar, Calculated Total Words from Distinct Words: 377\n",
      "Language: ar, Top 5 Words: [('هل', 50), ('في', 16), ('من', 8), ('يمكن', 6), ('مع', 3), ('هناك', 3), ('بين', 3), ('الهند', 3), ('أكثر', 3), ('تم', 3)]\n",
      "Language: ko, Distinct Words: 72\n",
      "Language: ko, Distinct Characters: 138\n",
      "Language: ko, Calculated Total Words from Distinct Words: 95\n",
      "Language: ko, Top 5 Words: [('있는가', 8), ('살', 3), ('수', 3), ('시차는', 2), ('중력과', 2), ('관련이', 2), ('있을까', 2), ('화성의', 2), ('대기에', 2), ('인간이', 2)]\n",
      "Language: te, Distinct Words: 186\n",
      "Language: te, Distinct Characters: 57\n",
      "Language: te, Calculated Total Words from Distinct Words: 561\n",
      "Language: te, Top 5 Words: [('ఎవరు', 25), ('ఏ', 20), ('ఏది', 19), ('ఎంత', 14), ('జనాభా', 11), ('నాటికి', 10), ('దేశం', 10), ('అతిపెద్ద', 9), ('దేశ', 8), ('విస్తీర్ణం', 8)]\n"
     ]
    }
   ],
   "source": [
    "# from googletrans import Translator\n",
    "\n",
    "def wordCount(df, lang):\n",
    "    allWords = []\n",
    "    df = df[df['lang'] == lang].copy()\n",
    "    \n",
    "    df = df[df['answerable'] == False]\n",
    "    df['question'] = df['question'].astype(str)\n",
    "\n",
    "    for q in df['question']:\n",
    "        allWords.extend(q.split()) \n",
    "    \n",
    "    wordDict = dict(Counter(allWords))\n",
    "    wordDict = dict(sorted(wordDict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return wordDict\n",
    "            \n",
    "\n",
    "for lang in langForStat:\n",
    "    wordDict = wordCount(df_val_clean, lang)\n",
    "    distinctWordCount.append((lang, len(wordDict)))\n",
    "    print(f\"Language: {lang}, Distinct Words: {len(wordDict)}\")\n",
    "\n",
    "    allChars = []\n",
    "    for word in wordDict.keys():\n",
    "        allChars.extend(list(word))\n",
    "    \n",
    "    charDict = dict(Counter(allChars))\n",
    "    charDict = dict(sorted(charDict.items(), key=lambda item: item[1], reverse=True))\n",
    "    distinctCharCount.append((lang, len(charDict)))\n",
    "    print(f\"Language: {lang}, Distinct Characters: {len(charDict)}\")\n",
    "    calculatedTotalWords = sum(wordDict.values())\n",
    "    print(f\"Language: {lang}, Calculated Total Words from Distinct Words: {calculatedTotalWords}\")\n",
    "\n",
    "    top5Words = list(wordDict.items())[:10]\n",
    "    print(f\"Language: {lang}, Top 5 Words: {top5Words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976793c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Classifier Accuracy (validation): 91.81%\n",
      "True distribution in validation set: {True: 0.8746987951807229, False: 0.12530120481927712}\n",
      "Korean Classifier Accuracy (validation): 94.66%\n",
      "True distribution in validation set: {True: 0.9466292134831461, False: 0.05337078651685393}\n",
      "Telugu Classifier Accuracy (validation): 79.17%\n",
      "True distribution in validation set: {True: 0.7578125, False: 0.2421875}\n"
     ]
    }
   ],
   "source": [
    "def arabicClassifier(question, context):\n",
    "    goodWords = ['متى','ما','هو','هي','كم','عدد','أول','في']\n",
    "    badWords = ['هل', 'يمكن']\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    elif any(word in question for word in badWords):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "def koreanClassifier(question, context):\n",
    "    goodWords = ['가장', '무엇인가', '언제', '몇']\n",
    "    badWords = [] # '시차는', '중력과'\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    elif any(word in question for word in badWords):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "    \n",
    "def teluguClassifier(question, context):\n",
    "    goodWords = []\n",
    "    badWords = ['విస్తీర్ణం', 'జనాభా', 'ఆఫ్రికాలో']\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    elif any(word in question for word in badWords):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "### --- Arabic ---\n",
    "arabicDf = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "arabicDf['prediction'] = arabicDf.apply(lambda row: arabicClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (arabicDf['answerable'] == arabicDf['prediction']).mean()\n",
    "print(f\"Arabic Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {arabicDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Korean ---\n",
    "koreanDf = df_val_clean[df_val_clean['lang'] == 'ko'].copy()\n",
    "koreanDf['prediction'] = koreanDf.apply(lambda row: koreanClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (koreanDf['answerable'] == koreanDf['prediction']).mean()\n",
    "print(f\"Korean Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {koreanDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Telugu ---\n",
    "teluguDf = df_val_clean[df_val_clean['lang'] == 'te'].copy()\n",
    "teluguDf['prediction'] = teluguDf.apply(lambda row: teluguClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (teluguDf['answerable'] == teluguDf['prediction']).mean()\n",
    "print(f\"Telugu Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {teluguDf['answerable'].value_counts(normalize=True).to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
