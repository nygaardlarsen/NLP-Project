{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7011378",
   "metadata": {},
   "source": [
    "NLP Project for KU Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecaf78ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andreasmelbye/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/andreasmelbye/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "/Users/andreasmelbye/miniconda3/envs/nlp_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk import FreqDist, ConditionalFreqDist\n",
    "\n",
    "\n",
    "## Load the dataset\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8e379",
   "metadata": {},
   "source": [
    "## Week 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c03e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unwanted characters from the questions\n",
    "\n",
    "def cleanDf(df):\n",
    "    pattern = re.compile(r\"[?؟,;\\/\\\\\\[\\]#():]\")\n",
    "    # pattern_context = re.compile(r\"[?؟,;\\/\\\\\\[\\]#():.]\")\n",
    "    df['question'] = df['question'].apply(lambda x: pattern.sub(\"\", x))\n",
    "    df['context'] = df['context'].apply(lambda x: pattern.sub(\"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feffa14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Train Questions: 2558, Validation Questions: 415\n",
      "Language: ar, Train Total Words: 16202, Validation Total Words: 2621\n",
      "Language: ko, Train Questions: 2422, Validation Questions: 356\n",
      "Language: ko, Train Total Words: 11840, Validation Total Words: 1729\n",
      "Language: te, Train Questions: 1355, Validation Questions: 384\n",
      "Language: te, Train Total Words: 7668, Validation Total Words: 2299\n"
     ]
    }
   ],
   "source": [
    "langForStat = ['ar','ko','te']\n",
    "\n",
    "numQuestions = []\n",
    "totalWordCount = []\n",
    "distinctWordCount = []\n",
    "distinctCharCount = []\n",
    "\n",
    "df_train_clean = cleanDf(df_train)\n",
    "df_val_clean = cleanDf(df_val)\n",
    "\n",
    "for lang in langForStat:\n",
    "    numQuestions_train = df_train_clean[df_train_clean['lang'] == lang].shape[0]\n",
    "    numQuestions_val = df_val_clean[df_val_clean['lang'] == lang].shape[0]\n",
    "    numQuestions.append((lang, numQuestions_train, numQuestions_val))\n",
    "    print(f\"Language: {lang}, Train Questions: {numQuestions_train}, Validation Questions: {numQuestions_val}\")\n",
    "\n",
    "    # Compute word and character statistics\n",
    "    df_train_lang = df_train_clean[df_train_clean['lang'] == lang].copy()\n",
    "    df_val_lang = df_val_clean[df_val_clean['lang'] == lang]\n",
    "    df_train_lang['wordcount'] = df_train_lang['question'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "\n",
    "    maxId = df_train_lang['wordcount'].idxmax()\n",
    "    longest_question = df_train_lang.loc[maxId, \"question\"]\n",
    "    max_words = df_train_lang.loc[maxId, \"wordcount\"]\n",
    "\n",
    "    # print(f\"Language: {lang}\")\n",
    "    # print(f\"  Longest train question (index {maxId}): {longest_question}\")\n",
    "    # print(f\"  Word count: {max_words}\")\n",
    "\n",
    "    totalWordCount_train = df_train_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount_val = df_val_lang['question'].apply(lambda x: len(x.split())).sum()\n",
    "    totalWordCount.append((lang, totalWordCount_train, totalWordCount_val))\n",
    "    print(f\"Language: {lang}, Train Total Words: {totalWordCount_train}, Validation Total Words: {totalWordCount_val}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74be8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar, Distinct Words: 5427\n",
      "Language: ar, Distinct Characters: 106\n",
      "Language: ar, Calculated Total Words from Distinct Words: 16202\n",
      "Language: ar, Top 5 Words: [('في', 592), ('من', 584), ('متى', 535), ('ما', 441), ('هو', 349), ('هل', 329), ('هي', 268), ('كم', 256), ('عدد', 161), ('أول', 157)]\n",
      "Language: ko, Distinct Words: 4394\n",
      "Language: ko, Distinct Characters: 819\n",
      "Language: ko, Calculated Total Words from Distinct Words: 11840\n",
      "Language: ko, Top 5 Words: [('가장', 527), ('무엇인가', 497), ('언제', 336), ('몇', 234), ('어디인가', 228), ('큰', 194), ('누구인가', 186), ('세상에서', 142), ('누구인가요', 105), ('무엇인가요', 95)]\n",
      "Language: te, Distinct Words: 2420\n",
      "Language: te, Distinct Characters: 91\n",
      "Language: te, Calculated Total Words from Distinct Words: 7668\n",
      "Language: te, Top 5 Words: [('ఎవరు', 274), ('ఏది', 192), ('ఎన్ని', 165), ('ఎప్పుడు', 154), ('ఏ', 142), ('ఎంత', 116), ('చిత్ర', 97), ('ఎక్కడ', 96), ('మొదటి', 86), ('ఉంది', 83)]\n"
     ]
    }
   ],
   "source": [
    "def wordCount(df, lang):\n",
    "    allWords = []\n",
    "    df = df[df['lang'] == lang].copy()\n",
    "    \n",
    "    # df = df[df['answerable'] == False]\n",
    "    df['question'] = df['question'].astype(str)\n",
    "\n",
    "    for q in df['question']:\n",
    "        allWords.extend(q.split()) \n",
    "    \n",
    "    wordDict = dict(Counter(allWords))\n",
    "    wordDict = dict(sorted(wordDict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return wordDict\n",
    "            \n",
    "\n",
    "for lang in langForStat:\n",
    "    wordDict = wordCount(df_train_clean, lang)\n",
    "    distinctWordCount.append((lang, len(wordDict)))\n",
    "    print(f\"Language: {lang}, Distinct Words: {len(wordDict)}\")\n",
    "\n",
    "    allChars = []\n",
    "    for word in wordDict.keys():\n",
    "        allChars.extend(list(word))\n",
    "    \n",
    "    charDict = dict(Counter(allChars))\n",
    "    charDict = dict(sorted(charDict.items(), key=lambda item: item[1], reverse=True))\n",
    "    distinctCharCount.append((lang, len(charDict)))\n",
    "    print(f\"Language: {lang}, Distinct Characters: {len(charDict)}\")\n",
    "    calculatedTotalWords = sum(wordDict.values())\n",
    "    print(f\"Language: {lang}, Calculated Total Words from Distinct Words: {calculatedTotalWords}\")\n",
    "\n",
    "    top5Words = list(wordDict.items())[:10]\n",
    "    print(f\"Language: {lang}, Top 5 Words: {top5Words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976793c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Classifier Accuracy (validation): 96.87%\n",
      "True distribution in validation set: {True: 0.8746987951807229, False: 0.12530120481927712}\n",
      "Korean Classifier Accuracy (validation): 94.94%\n",
      "True distribution in validation set: {True: 0.9466292134831461, False: 0.05337078651685393}\n",
      "Telugu Classifier Accuracy (validation): 79.17%\n",
      "True distribution in validation set: {True: 0.7578125, False: 0.2421875}\n"
     ]
    }
   ],
   "source": [
    "def arabicClassifier(question, context):\n",
    "    goodWords = ['متى','ما','هو','هي','كم','عدد','أول','في']\n",
    "    badWords = ['هل', 'يمكن']\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "def koreanClassifier(question, context):\n",
    "    goodWords = ['가장', '무엇인가', '언제', '몇']\n",
    "    badWords = ['수 '] # '시차는', '중력과'\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "    \n",
    "def teluguClassifier(question, context):\n",
    "    goodWords = []\n",
    "    badWords = ['విస్తీర్ణం', 'జనాభా', 'ఆఫ్రికాలో']\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "            return True\n",
    "    # if any(word in question for word in badWords):\n",
    "    #     return False\n",
    "    else:\n",
    "        return True\n",
    "        # return np.random.choice([True, False])\n",
    "\n",
    "### --- Arabic ---\n",
    "arabicDf = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "arabicDf['prediction'] = arabicDf.apply(lambda row: arabicClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (arabicDf['answerable'] == arabicDf['prediction']).mean()\n",
    "print(f\"Arabic Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {arabicDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Korean ---\n",
    "koreanDf = df_val_clean[df_val_clean['lang'] == 'ko'].copy()\n",
    "koreanDf['prediction'] = koreanDf.apply(lambda row: koreanClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (koreanDf['answerable'] == koreanDf['prediction']).mean()\n",
    "print(f\"Korean Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {koreanDf['answerable'].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "### --- Telugu ---\n",
    "teluguDf = df_val_clean[df_val_clean['lang'] == 'te'].copy()\n",
    "teluguDf['prediction'] = teluguDf.apply(lambda row: teluguClassifier(row['question'], row['context']), axis=1)\n",
    "accuracy = (teluguDf['answerable'] == teluguDf['prediction']).mean()\n",
    "print(f\"Telugu Classifier Accuracy (validation): {accuracy * 100:.2f}%\")\n",
    "print(f\"True distribution in validation set: {teluguDf['answerable'].value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e06111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Classifier Accuracy (validation): 96.87%\n"
     ]
    }
   ],
   "source": [
    "def overlap_ratio(question, context):\n",
    "    q_words = set(question.split())\n",
    "    c_words = set(context.split())\n",
    "    if not q_words: return 0\n",
    "    return len(q_words & c_words) / len(q_words)\n",
    "\n",
    "\n",
    "import re\n",
    "def contains_digit(text):\n",
    "    return bool(re.search(r\"\\d+\", text))\n",
    "\n",
    "\n",
    "def arabicClassifier(question, context):\n",
    "    goodWords = ['متى','ما','هو','هي','كم','عدد','أول','في']\n",
    "    badWords = ['هل', 'يمكن']\n",
    "    \n",
    "    # Rule 1: keyword spotting\n",
    "    if any(word in question for word in badWords):\n",
    "        return False\n",
    "    if any(word in question for word in goodWords):\n",
    "        return True\n",
    "    \n",
    "    # # Rule 2: overlap\n",
    "    # if overlap_ratio(question, context) < 0.1:\n",
    "    #     return False\n",
    "    \n",
    "    # # Rule 3: digits\n",
    "    # if contains_digit(question) and not contains_digit(context):\n",
    "    #     return False\n",
    "    \n",
    "    # Rule 4: context length\n",
    "    if len(context.split()) < 25:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Arabic\n",
    "arabicDf = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "arabicDf['prediction'] = arabicDf.apply(lambda row: arabicClassifier(row['question'], row['context']), axis=1)\n",
    "arabic_acc = (arabicDf['answerable'] == arabicDf['prediction']).mean()\n",
    "print(f\"Arabic Classifier Accuracy (validation): {arabic_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a39729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answerable",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "answer_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer_inlang",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "dabcb2eb-0b04-48dc-a657-6b27262be17d",
       "rows": [
        [
         "0",
         "ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది ",
         "Portland is the largest city in the U.S. state of Oregon and the seat of Multnomah County. It is a major port in the Willamette Valley region of the Pacific Northwest at the confluence of the Willamette and Columbia rivers. As of 2017 Portland had an estimated population of 647805 making it the 26th-largest city in the United States and the second-most populous in the Pacific Northwest after Seattle. Approximately 2.4 million people live in the Portland metropolitan statistical area MSA making it the 25th most populous MSA in the United States. Its Combined Statistical Area CSA ranks 18th-largest with a population of around 3.2 million. Approximately 60% of Oregon's population resides within the Portland metropolitan area.",
         "te",
         "True",
         "0",
         "Portland",
         null
        ],
        [
         "1",
         "కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ",
         "The word cholera is from \"kholera\" from χολή \"kholē\" \"bile\". Cholera likely has its origins in the Indian subcontinent as evidenced by its prevalence in the region for centuries. Early outbreaks in the Indian subcontinent are believed to have been the result of poor living conditions as well as the presence of pools of still water both of which provide ideal conditions for cholera to thrive. The disease first spread by trade routes land and sea to Russia in 1817 later to the rest of Europe and from Europe to North America and the rest of the world. Seven cholera pandemics have occurred in the past 200 years with the seventh pandemic originating in Indonesia in 1961.",
         "te",
         "True",
         "99",
         "Indian subcontinent",
         null
        ],
        [
         "2",
         "కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ",
         "Since it became widespread in the 19th century cholera has killed tens of millions of people. In Russia alone between 1847 and 1851 more than one million people perished of the disease. It killed 150000 Americans during the second pandemic. Between 1900 and 1920 perhaps eight million people died of cholera in India. Cholera became the first reportable disease in the United States due to the significant effects it had on health. John Snow in England was the first to identify the importance of contaminated water as its cause in 1854. Cholera is now no longer considered a pressing health threat in Europe and North America due to filtering and chlorination of water supplies but still heavily affects populations in developing countries.",
         "te",
         "True",
         "451",
         "England",
         null
        ],
        [
         "3",
         "మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ",
         "World War I occurred from 1914 to 1918. In terms of human technological history the scale of World War I was enabled by the technological advances of the second industrial revolution and the resulting globalization that allowed global power projection and mass production of military hardware. Wars on such a scale have not been repeated since the onset of the Atomic Age and the resulting danger of mutually-assured destruction. It had been recognized that the complex system of opposing alliances the German Austro-Hungarian and Ottoman Empires against the British Russian and French Empires was likely to lead to a worldwide conflict if a war broke out. Due to this fact a very minute conflict between two countries had the potential to set off a domino effect of alliances triggering a world war. The fact that the powers involved had large overseas empires virtually guaranteed that such a war would be worldwide as the colonies' resources would be a crucial strategic factor. The same strategic considerations also ensured that the combatants would strike at each other's colonies thus spreading the wars far more widely than those of pre-Columbian times.",
         "te",
         "True",
         "26",
         "1914",
         null
        ],
        [
         "4",
         "మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ",
         "World War I often abbreviated as WWI or WW1 also known as the First World War or the Great War was a global war originating in Europe that lasted from 28 July 1914 to 11 November 1918. Contemporaneously described as \"the war to end all wars\" it led to the mobilisation of more than 70 million military personnel including 60 million Europeans making it one of the largest wars in history. It is also one of the deadliest conflicts in history with an estimated nine million combatants and seven million civilian deaths as a direct result of the war while resulting genocides and the 1918 influenza pandemic caused another 50 to 100 million deaths worldwide.",
         "te",
         "True",
         "155",
         "28 July 1914",
         null
        ],
        [
         "5",
         "సమాచార చట్టం-2005 ను ఏ ప్రభుత్వం ఆమోదించింది",
         "The Right to Information Act RTI Act was passed by Parliament on 11 May 2005 and was published in the gazette of India on 15 June 2005. It came into effect on 12 October 2005 replacing the erstwhile Freedom of information Act 2002. The Supreme Court of India had in several Judgments prior to enactment of both Acts interpreted Indian Constitution to read Right to Information as the Fundamental Right as embodied in Right to Freedom of Speech and Expression and also in Right to Life. RTI Act laid down a procedure to guarantee this right. Under this law all Government Bodies or Government funded agencies have to designate a Public Information Officer PIO. The PIO's responsibility is to ensure that information requested is disclosed to the petitioner within 30 days or within 48 hours in case of information concerning the life or liberty of a person. The law was inspired by previous legislation from select states among them Tamil Nadu 1997 Goa 1997 Rajasthan 2000 Karnataka 2000 Delhi 2001 Maharashtra 2002 etc. that allowed the right to information to different degrees to citizens about activities of any State Government body.",
         "te",
         "True",
         "115",
         "India",
         null
        ],
        [
         "6",
         "ప్రాచీన భారతదేశంలో ఎన్ని భాషలు వాడుకలో ఉండేవి",
         "According to the Census of India of 2001 India has 122 major languages and 1599 other languages. However figures from other sources vary primarily due to differences in definition of the terms \"language\" and \"dialect\". The 2001 Census recorded 30 languages which were spoken by more than a million native speakers and 122 which were spoken by more than 10000 people. Two contact languages have played an important role in the history of India Persian and English. Persian was the court language during the Mughal period in India. It reigned as an administrative language for several centuries until the era of British colonisation. English continues to be an important language in India. It is used in higher education and in some areas of the Indian government. Hindi the most commonly spoken language in India today serves as the \"lingua franca\" across much of North and Central India. However there have been anti-Hindi agitations in South India most notably in the state of Tamil Nadu and Karnataka. Maharashtra West Bengal Assam Punjab and other non-Hindi regions have also started to voice concerns about Hindi.",
         "te",
         "True",
         "52",
         "122",
         null
        ],
        [
         "7",
         "మనిషిని సగటున ఉండాల్సిన రక్తం ఎంత",
         "A typical adult has a blood volume of approximately 5 liters with females and males having approximately the same blood volume. Blood volume is regulated by the kidneys.",
         "te",
         "True",
         "38",
         "approximately 5 liters",
         null
        ],
        [
         "8",
         "టెక్సస్ రాష్ట్రంలోని అతిపెద్ద మానవ నిర్మితం ఏది ",
         "In the 1960s Downtown Houston consisted of a collection of midrise office structures. Downtown was on the threshold of an energy industryled boom in 1970. A succession of skyscrapers was built throughout the 1970s—many by real estate developer Gerald D. Hines—culminating with Houston's tallest skyscraper the 75-floor -tall JPMorgan Chase Tower formerly the Texas Commerce Tower completed in 1982. It is the tallest structure in Texas 15th tallest building in the United States and the 85th-tallest skyscraper in the world based on highest architectural feature. In 1983 the 71-floor -tall Wells Fargo Plaza formerly Allied Bank Plaza was completed becoming the second-tallest building in Houston and Texas. Based on highest architectural feature it is the 17th-tallest in the United States and the 95th-tallest in the world. In 2007 Downtown had over 43 million square feet 4000000 m² of office space.",
         "te",
         "True",
         "328",
         "JPMorgan Chase Tower",
         null
        ],
        [
         "9",
         "భారతదేశంలో ఓటు హక్కు పొందడానికి ఉండవలసిన కనీస వయస్సు ఎంత",
         "The Sixty-first Amendment of the Constitution of India officially known as The Constitution Sixty-first Amendment Act 1988 lowered the voting age of elections to the Lok Sabha and to the Legislative Assemblies of States from 21 years to 18 years. This was done by amending Article 326 of the Constitution which concerns elections to the Lok Sabha and the Assemblies.",
         "te",
         "True",
         "242",
         "18",
         null
        ],
        [
         "10",
         "టెలివిజన్ ను ఏ సంవత్సరంలో కనుగొన్నారు",
         "John Logie Baird  13 August 188814 June 1946 was a Scottish engineer innovator one of the inventors of the mechanical television demonstrating the first working television system on 26 January 1926 and inventor of both the first publicly demonstrated colour television system and the first purely electronic colour television picture tube.",
         "te",
         "True",
         "199",
         "1926",
         null
        ],
        [
         "11",
         "భారతదేశంలో వరి ఎక్కువగా పండే రాష్ట్రం ఏది",
         "India has the largest paddy output in the world and is also the fourth largest exporter of rice in the world. In India West Bengal is the largest rice producing state. Paddy fields are a common sight throughout India both in the northern gangetic plains and the southern peninsular plateaus. Paddy is cultivated at least twice a year in most parts of India the two seasons being known as Rabi and Kharif respectively. The former cultivation is dependent on irrigation while the latter depends on Monsoon. The paddy cultivation plays a major role in socio-cultural life of rural India. Many festivals such as Onam in Kerala Bihu in Assam Makara Sankranthi in Andhra Pradesh and Telangana Thai Pongal In Tamil Nadu Makar Sankranti in Karnataka Nabanna in West Bengal celebrates harvest of Paddy. Kaveri delta region of Thanjavur is historically known as the rice bowl of Tamil Nadu and Kuttanadu is called the rice bowl of Kerala.",
         "te",
         "True",
         "120",
         "West Bengal",
         null
        ],
        [
         "12",
         "భారతదేశంలో సగటుగా ఎన్ని భాషలు మాట్లాడతారు",
         "According to the Census of India of 2001 India has 122 major languages and 1599 other languages. However figures from other sources vary primarily due to differences in definition of the terms \"language\" and \"dialect\". The 2001 Census recorded 30 languages which were spoken by more than a million native speakers and 122 which were spoken by more than 10000 people. Two contact languages have played an important role in the history of India Persian and English. Persian was the court language during the Mughal period in India. It reigned as an administrative language for several centuries until the era of British colonisation. English continues to be an important language in India. It is used in higher education and in some areas of the Indian government. Hindi the most commonly spoken language in India today serves as the \"lingua franca\" across much of North and Central India. However there have been anti-Hindi agitations in South India most notably in the state of Tamil Nadu and Karnataka. Maharashtra West Bengal Assam Punjab and other non-Hindi regions have also started to voice concerns about Hindi.",
         "te",
         "True",
         "321",
         "122 which were spoken by more than 10,000 people",
         null
        ],
        [
         "13",
         "వాటికన్ సిటి లో పేరుగాంచిన చర్చ్ ఏది",
         "The Papal Basilica of St. Peter in the Vatican  or simply St. Peter's Basilica  is an Italian Renaissance church in Vatican City the papal enclave within the city of Rome.",
         "te",
         "True",
         "61",
         "St. Peter's Basilica",
         null
        ],
        [
         "14",
         "ఈజిప్టు దేశపు ఇంటర్నెట్ డొమైన్ కోడ్ ఏంటి",
         ".eg is the Latin alphabet country code top-level domain ccTLD for Egypt. Any entity who wants to register a domain name ending with codice_1 must have a local representative or the domain name has to be hosted on Egyptian DNS servers. Egypt's Arabic alphabet ccTLD is codice_2‎. During the 2011 Egyptian protests domain .eg was shut down by the government.",
         "te",
         "True",
         "0",
         ".eg",
         null
        ],
        [
         "15",
         "కాలిఫోర్నియాలో రాష్ట్రంలో విస్తీర్ణం పరంగా అతి పెద్ద నగరం ఏది",
         "San Jose is located at . According to the United States Census Bureau the city has a total area of  of which 1.91% is water making it the fourth-largest California city by land area after Los Angeles San Diego and California City.",
         "te",
         "True",
         "194",
         "Los Angeles",
         null
        ],
        [
         "16",
         "2010 నాటికి భారతదేశంలో క్రైస్తవులు ఎక్కువ ఉండే ప్రాంతం ఏది",
         "Even though Christians are a significant minority they form a major religious group in three states of India - Meghalaya Mizoram and Nagaland with plural majority in Manipur and Arunachal Pradesh and other states with significant Christian population include Coastal Andhra Tamil Nadu Kerala and Kanara. Christianity is widespread across India and is present in all states with major populations in South India.",
         "te",
         "True",
         "112",
         "Meghalaya, Mizoram, and Nagaland",
         null
        ],
        [
         "17",
         "ఉగాండా ఏ ఖండంలో ఉంది",
         "Uganda officially the Republic of Uganda  is a landlocked country except for its borders with Lake Victoria and Lake Albert in East-Central Africa. It is bordered to the east by Kenya to the north by South Sudan to the west by the Democratic Republic of the Congo to the south-west by Rwanda and to the south by Tanzania. The southern part of the country includes a substantial portion of Lake Victoria shared with Kenya and Tanzania. Uganda is in the African Great Lakes region. Uganda also lies within the Nile basin and has a varied but generally a modified equatorial climate.",
         "te",
         "True",
         "146",
         "Africa",
         null
        ],
        [
         "18",
         "ఖురాన్ ఏ అరబ్బీ భాషలో ఎవరు రాసారు",
         "Muslims believe that the Quran was orally revealed by God to the final Prophet Muhammad through the archangel Gabriel \"Jibril\" incrementally over a period of some 23 years beginning on 22 December 609 CE when Muhammad was 40 and concluding in 632 the year of his death. Muslims regard the Quran as Muhammad's most important miracle a proof of his prophethood and the culmination of a series of divine messages starting with those revealed to Adam and ending with Muhammad. The word \"Quran\" occurs some 70 times in the Quran's text and other names and words are also said to refer to the Quran.",
         "te",
         "True",
         "80",
         "Muhammad",
         null
        ],
        [
         "19",
         "జలం ని ఆంగ్లంలో ఏమని అంటారు",
         "The word \"water\" comes from Old English \"wæter\" from Proto-Germanic \"*watar\" source also of Old Saxon \"watar\" Old Frisian \"wetir\" Dutch \"water\" Old High German \"wazzar\" German \"Wasser\" Old Norse \"vatn\" Gothic \"wato\" from Proto-Indoeuropean \"*wod-or\" suffixed form of root \"*wed-\" \"water\" \"wet\".",
         "te",
         "True",
         "10",
         "water",
         null
        ],
        [
         "20",
         "భారతదేశంలో క్రైస్తవ మిషనరీ మొదటగా ఎక్కడ స్థాపించబడింది ",
         "Christianity is India's third most followed religion according to the census of 2011 with approximately 28 million followers constituting 2.3 percent of India's population. It is traditionally believed that Christianity was introduced to India by Thomas the Apostle who supposedly landed in Kerala in 52 AD. There is a general scholarly consensus that Christianity was established in India by the 6th century AD including some communities who used Syriac liturgies. It is possible that the religion's existence extends as far back as the purported time of St. Thomas's arrival.",
         "te",
         "True",
         "400",
         "6th century AD",
         null
        ],
        [
         "21",
         "పురాణాల ప్రకారం విష్ణువు అవతారాలలో కృష్ణుడి అవతారం ఎన్నవది",
         "Krishna    is a major deity in Hinduism. He is worshipped as the eighth avatar of the god Vishnu and also by some as the supreme God in his own right. He is the god of compassion tenderness and love in Hinduism and is one of the most popular and widely revered among Indian divinities. Krishna's birthday is celebrated every year by Hindus on Janmashtami according to the lunisolar Hindu calendar which falls in late August or early September of the Gregorian calendar.",
         "te",
         "True",
         "69",
         "eighth",
         null
        ],
        [
         "22",
         "ఒక మనిషి సగటుగా ఎంత ఉష్ణోగ్రతని తట్టుకోగలడు",
         "The human body always works to remain in homeostasis. One form of homeostasis is thermoregulation. Body temperature varies in every individual but the average internal temperature is 37.0 °C 98.6 °F. Stress from extreme external temperature can cause the human body to shut down. Hypothermia can set in when the core temperature drops to 35 °C 95 °F. Hyperthermia can set in when the core body temperature rises above 37.5-38.3 °C 99.5-100.9 °F. These temperatures commonly result in mortality. Humans have adapted to living in climates where hypothermia and hyperthermia are common primarily through culture and technology such as the use of clothing and shelter.",
         "te",
         "True",
         "184",
         "37.0 °C (98.6 °F)",
         null
        ],
        [
         "23",
         "క్యాన్సర్ ని కనుగొన్నది ఎవరు",
         "Cancer has existed for all of human history. The earliest written record regarding cancer is from circa 1600 BC in the Egyptian Edwin Smith Papyrus and describes breast cancer. Hippocrates c. 460 BC – c. 370 BC described several kinds of cancer referring to them with the Greek word καρκίνος \"karkinos\" crab or crayfish. This name comes from the appearance of the cut surface of a solid malignant tumor with \"the veins stretched on all sides as the animal the crab has its feet whence it derives its name\". Galen stated that \"cancer of the breast is so called because of the fancied resemblance to a crab given by the lateral prolongations of the tumor and the adjacent distended veins\". Celsus c. 25 BC – 50 AD translated \"karkinos\" into the Latin \"cancer\" also meaning crab and recommended surgery as treatment. Galen 2nd century AD disagreed with the use of surgery and recommended purgatives instead. These recommendations largely stood for 1000 years.",
         "te",
         "True",
         "177",
         "Hippocrates",
         null
        ],
        [
         "24",
         "ప్రాచీన గ్రీకు ఏ కాలం నుండి ఏ కాలం వరకు నడిచింది",
         "Ancient Greece  was a civilization belonging to a period of Greek history from the Greek Dark Ages of the 12th–9th centuries BC to the end of antiquity  AD 600. Immediately following this period was the beginning of the Early Middle Ages and the Byzantine era. Roughly three centuries after the Late Bronze Age collapse of Mycenaean Greece Greek urban poleis began to form in the 8th century BC ushering in the Archaic period and colonization of the Mediterranean Basin. This was followed by the period of Classical Greece an era that began with the Greco-Persian Wars lasting from the 5th to 4th centuries BC. Due to the conquests by Alexander the Great of Macedon Hellenistic civilization flourished from Central Asia to the western end of the Mediterranean Sea. The Hellenistic period came to an end with the conquests and annexations of the eastern Mediterranean world by the Roman Republic which established the Roman province of Macedonia in Roman Greece and later the province of Achaea during the Roman Empire.",
         "te",
         "True",
         "91",
         "Dark Ages of the 12th–9th centuries BC to the end of antiquity ( AD 600)",
         null
        ],
        [
         "25",
         "భారతదేశంలో మొదటగా మెట్రోరైలు ఏ రాష్ట్రంలో ప్రారంభమైంది",
         "The Kolkata Metro is a rapid transit system serving the Kolkata metropolitan area in the Indian state of West Bengal. The network currently consists of one operational line of 27.22 km from Noapara to Kavi Subhash with five other lines in various phases of construction. The Kolkata Metro was the first metro railway in India opening for commercial services from 1984. On 29 December 2010 Metro Railway Kolkata became the 17th zone of the Indian Railways operated by the Ministry of Railways. There are 300 metro services daily carrying over 700000 passengers making it the second busiest metro system in India.",
         "te",
         "True",
         "105",
         "West Bengal",
         null
        ],
        [
         "26",
         "మనిషి చనిపోయాక ఏ అవయవం ఎక్కువ సమయం పనిచేస్తుంది",
         "Most tissues and organs of the body can survive clinical death for considerable periods. Blood circulation can be stopped in the entire body below the heart for at least 30 minutes with injury to the spinal cord being a limiting factor. Detached limbs may be successfully reattached after 6 hours of no blood circulation at warm temperatures. Bone tendon and skin can survive as long as 8 to 12 hours.",
         "te",
         "True",
         "201",
         "spinal cord",
         null
        ],
        [
         "27",
         "ఆక్సిజన్ చిత్ర కధానాయకుడు ఎవరు",
         "Anu Emmanuel is an actress who appears in South Indian films. She made her acting debut as a child artist in the Malayalam film \"Swapna Sanchari\" produced by her father Thankachan Emmanuel who hails from Kottayam Kerala in 2011 playing the daughter of Jayaram and Samvrutha Sunil in the film. She made her debut as a heroine in the 2016 Malayalam film \"Action Hero Biju\". She made her Telugu debut with \"Majnu\" 2016 and went on to act in other Telugu films like \"Kittu Unnadu Jagratha\" 2017 \"Oxygen\" and \"Agnyaathavaasi\" 2018. Emmanuel has also worked in Tamil films making her debut with the suspense thriller \"Thupparivaalan\" 2017.",
         "te",
         "True",
         "0",
         "Anu Emmanuel",
         null
        ],
        [
         "28",
         "ఆక్సిజన్ చిత్ర కధానాయకుడు ఎవరు",
         "Emmanuel was born in the US and lived most of her childhood in Dallas Texas. She acted in \"Swapna Sanchari\" while she was attending school in India. Upon completion of the film she went back to US to finish her high school. While in high school Anu knew she wanted to pursue something in the artistic field. She made her acting debut as lead in Nivin Pauly starrer \"Action Hero Biju\" which was directed by Abrid Shine. During that time she was announced as the female lead in \"Oxygen\" alongside actor Gopichand in the lead. During the shoot of that film she signed \"Majnu\" alongside actor Nani. Emmanuel received much critical praise for her role and performance in the film. She immediately went on to the big league by signing Pawan Kalyan and Trivikram's film Agnyaathavaasi followed by a film starring Allu Arjun called \"Naa Peru Surya\". However these films did not perform very well at the box office.",
         "te",
         "True",
         "505",
         "Gopichand",
         null
        ],
        [
         "29",
         "2018 వరకు బైబిలు ను ఎన్ని భాషలలో అనువదించారు",
         "The Bible has been translated into many languages from the biblical languages of Hebrew Aramaic and Greek. the full Bible has been translated into 670 languages the New Testament has been translated into 1521 languages and Bible portions or stories into 1121 other languages. Thus at least some portion of the Bible has been translated into 3312 languages.",
         "te",
         "True",
         "345",
         "3,312 languages",
         null
        ],
        [
         "30",
         "నీతిని ఆంగ్లంలో ఏమంటారు",
         "The English word \"ethics\" is derived from the Ancient Greek word \"ēthikós\"  meaning \"relating to one's character\" which itself comes from the root word \"êthos\"  meaning \"character moral nature\". This was borrowed into Latin as \"ethica\" and then into French as \"éthique\" from which it was borrowed into English.",
         "te",
         "True",
         "18",
         "ethics",
         null
        ],
        [
         "31",
         "అమెరికాలో ఎన్ని నదులు ప్రవహిస్తున్నాయి",
         "The main stems of 38 rivers in the United States are at least long. The main stem is \"the primary downstream segment of a river as contrasted to its tributaries\". The United States Geological Survey USGS defines a main-stem segment by listing coordinates for its two end points called the \"source\" and the \"mouth\". Well-known rivers like the Atchafalaya Willamette and Susquehanna are not included in this list because their main stems are shorter than 500 miles.",
         "te",
         "True",
         "18",
         "38",
         null
        ],
        [
         "32",
         "ప్రాచీన భారతదేశానికి రాజధాని ఏది",
         "Indraprastha \"Plain of Indra\" or \"City of Indra\" is mentioned in ancient Indian literature as a city of the Kuru Kingdom. It was the capital of the kingdom led by the Pandavas in the \"Mahabharata\" epic. Under the Pali form of its name Indapatta it is also mentioned in Buddhist texts as the capital of the Kuru mahajanapada. It is often thought to have been located in the region of present-day New Delhi particularly the Old Fort Purana Qila although this has not been conclusively confirmed. The city is sometimes also known as \"Khandavaprastha\" the name of a forest region on the banks of Yamuna river which according to the \"Mahabharata\" had been cleared to build the city.",
         "te",
         "True",
         "0",
         "Indraprastha",
         null
        ],
        [
         "33",
         "సాధారణ మానవునికి ఎన్ని గంటల నిద్ర అవసరం ",
         "Humans are generally diurnal. The average sleep requirement is between seven and nine hours per day for an adult and nine to ten hours per day for a child elderly people usually sleep for six to seven hours. Having less sleep than this is common among humans even though sleep deprivation can have negative health effects. A sustained restriction of adult sleep to four hours per day has been shown to correlate with changes in physiology and mental state including reduced memory fatigue aggression and bodily discomfort. During sleep humans dream. In dreaming humans experience sensory images and sounds in a sequence which the dreamer usually perceives more as an apparent participant than as an observer. Dreaming is stimulated by the pons and mostly occurs during the REM phase of sleep.",
         "te",
         "True",
         "63",
         "between seven and nine hours per day for an adult and nine to ten hours per day for a child",
         null
        ],
        [
         "34",
         "సాధారణ మానవునికి ఎన్ని గంటల నిద్ర అవసరం ",
         "Researchers have found that sleeping 6–7 hours each night correlates with longevity and cardiac health in humans though many underlying factors may be involved in the causality behind this relationship.",
         "te",
         "True",
         "37",
         "6–7",
         null
        ],
        [
         "35",
         "2011 నాటికి రష్యా దేశ ప్రధాన మంత్రి ఎవరు",
         "On September 27 2011 the Prime Minister of Russia Vladimir Putin appointed him as Acting Minister of Finance of Russia replacing in office the long-term minister Alexei Kudrin. Prime Minister Vladimir Putin who announced the appointment at a government meeting in September 27 2011 after it was approved by Medvedev said Siluanov was a “good solid specialist.” First Deputy Prime Minister Igor Shuvalov will take over the responsibilities Kudrin had as the deputy prime minister in charge of the economy. Alexey Kudrin will be replaced by Anton Siluanov in International Monetary Fund World Bank and in Eurasian Anticrisis economic Fund — ACF Антикризисном фонде ЕврАзЭС under Eurasian Development Bank.",
         "te",
         "True",
         "52",
         "Vladimir Putin",
         null
        ],
        [
         "36",
         "రెండవ ప్రపంచయుద్ధంలో సగటుగా ఎంతమంది చనిపోయారు",
         "World War II was the deadliest military conflict in history. An estimated total 70-85 million people perished which was about 3% of the 1940 world population est. 2.3 billion.",
         "te",
         "True",
         "80",
         "70-85 million",
         null
        ],
        [
         "37",
         "గాంధీజీని చంపిన వ్యక్తి పేరేమిటి",
         "Mahatma Gandhi was assassinated on 30 January 1948 in the compound of Birla House now Gandhi Smriti a large mansion. His assassin was Nathuram Vinayak Godse advocate of Indian nationalism a member of the political party the Hindu Mahasabha and a past member of the Rashtriya Swayamsevak Sangh RSS which he left in 1940 to form an armed organization. Godse had planned the assassination. ",
         "te",
         "True",
         "137",
         "Nathuram Vinayak Godse",
         null
        ],
        [
         "38",
         "గాంధీజీని చంపిన వ్యక్తి పేరేమిటి",
         "Nathuram Vinayak Godse 19 May 1910 – 15 November 1949 was a right-wing advocate of Hindu nationalism who assassinated Mahatma Gandhi in New Delhi on 30 January 1948. He shot Gandhi in the chest three times at point-blank range. Godse was a member of the right-wing nationalist organisation RSS he believed that Gandhi favoured the political demands of India's Muslims during the partition of India.",
         "te",
         "True",
         "0",
         "Nathuram Vinayak Godse",
         null
        ],
        [
         "39",
         "బ్రిటిష్ పాలనలో సగటున ఎంతమంది భారతీయులు మరణించారు",
         "The British Indian Army fought in Ethiopia against the Italian Army in Egypt Libya Tunisia and Algeria against both the Italian and German Army and after the Italian surrender against the German Army in Italy. However the bulk of the Indian Army was committed to fighting the Japanese Army first during the British defeats in Malaya and the retreat from Burma to the Indian border later after resting and refitting for the victorious advance back into Burma as part of the largest British Empire army ever formed. These campaigns cost the lives of over 87000 Indian servicemen while another 34354 were wounded and 67340 became prisoners of war. Their valour was recognised with the award of some 4000 decorations and 18 members of the Indian Army were awarded the Victoria Cross or the George Cross. Field Marshal Claude Auchinleck Commander-in-Chief of the Indian Army from 1942 asserted that the British \"couldn't have come through both wars World War I and II if they hadn't had the Indian Army.\" British Prime Minister Winston Churchill also paid tribute to \"The unsurpassed bravery of Indian soldiers and officers.\"",
         "te",
         "True",
         "564",
         "87,000",
         null
        ],
        [
         "40",
         "భారతదేశంలో మొత్తం ఎన్ని రకాల పూలు దొరుకుతాయి",
         "The flora of India is one of the richest in the world due to the wide range of climate topology and habitat in the country. There are estimated to be over 18000 species of flowering plants in India which constitute some 6-7 percent of the total plant species in the world. India is home to more than 50000 species of plants including a variety of endemics. The use of plants as a source of medicines has been an integral part of life in India from the earliest times. There are more than 3000 Indian plant species officially documented as possessing into eight main floristic regions  Western Himalayas Eastern Himalayas Assam Indus plain Ganges plain the Deccan Malabar and the Andaman Islands.",
         "te",
         "True",
         "156",
         "18,000",
         null
        ],
        [
         "41",
         "పర్యావరణంలో ఎక్కువగా ఉండే వాయువు ఏది ",
         "By volume dry air contains 78.09% nitrogen 20.95% oxygen 0.93% argon 0.04% carbon dioxide and small amounts of other gases. Air also contains a variable amount of water vapor on average around 1% at sea level and 0.4% over the entire atmosphere. Air content and atmospheric pressure vary at different layers and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.",
         "te",
         "True",
         "35",
         "nitrogen",
         null
        ],
        [
         "42",
         "అత్యంత శక్తివంతమైన నావికా రక్షణ దళం ఏ దేశానికి ఉంది",
         "In the beginning of World War II the Royal Navy was still the strongest navy in the world with the largest number of warships built and with naval bases across the globe. Totalling over 15 battleships and battlecruisers 7 aircraft carriers 66 cruisers 164 destroyers and 66 submarines. In the course of the war the United States Navy grew tremendously as the United States was faced with a two-front war on the seas. By the end of World War II the U.S Navy was larger than any other navy in the world.",
         "te",
         "True",
         "319",
         "United States Navy",
         null
        ],
        [
         "43",
         "అత్యంత శక్తివంతమైన నావికా రక్షణ దళం ఏ దేశానికి ఉంది",
         "The United States Navy USN is the naval warfare service branch of the United States Armed Forces and one of the seven uniformed services of the United States. It is the largest and most capable navy in the world with the highest combined battle fleet tonnage and the world's largest aircraft carrier fleet with eleven in service and two new carriers under construction. With 319421 personnel on active duty and 99616 in the Ready Reserve the Navy is the third largest of the service branches. It has 282 deployable combat vessels and more than 3700 operational aircraft  making it the second largest and second most powerful air force in the world. The U.S. Navy traces its origins to the Continental Navy which was established during the American Revolutionary War and was effectively disbanded as a separate entity shortly thereafter. The U.S. Navy played a major role in the American Civil War by blockading the Confederacy and seizing control of its rivers. It played the central role in the World War II defeat of Imperial Japan. The US Navy emerged from World War II as the most powerful navy in the world a title it still holds to this day. The 21st century U.S. Navy maintains a sizable global presence deploying in strength in such areas as the Western Pacific the Mediterranean and the Indian Ocean. It is a blue-water navy with the ability to project force onto the littoral regions of the world engage in forward deployments during peacetime and rapidly respond to regional crises making it a frequent actor in U.S. foreign and military policy. The Navy is administratively managed by the Department of the Navy which is headed by the civilian Secretary of the Navy. The Department of the Navy is itself a division of the Department of Defense which is headed by the Secretary of Defense. The Chief of Naval Operations CNO is the most senior naval officer serving in the Department of the Navy.",
         "te",
         "True",
         "0",
         "The United States Navy",
         null
        ],
        [
         "44",
         "మొదటి ప్రపంచ యుద్ధం మొదటగా ఏఏ దేశాల మధ్య మొదలు అయ్యింది",
         "The causes of World War I remain controversial. World War I began in the Balkans in late July 1914 and ended in November 1918 leaving 17 million dead and 20 million wounded.",
         "te",
         "True",
         "48",
         "World War I began in the Balkans in late July 1914 and ended in November 1918",
         null
        ],
        [
         "45",
         "మొదటి ప్రపంచ యుద్ధం మొదటగా ఏఏ దేశాల మధ్య మొదలు అయ్యింది",
         "Consensus on the origins of the war remains elusive since historians disagree on key factors and place differing emphasis on a variety of factors. This is compounded by changing historical arguments over time particularly the delayed availability of classified historical archives. The deepest distinction among historians is between those who focus on the actions of Germany and Austria-Hungary as key and those who focus on a wider group of actors. Secondary fault lines exist between those who believe that Germany deliberately planned a European war those who believe that the war was ultimately unplanned but still caused principally by Germany and Austria-Hungary taking risks and those who believe that either all or some of the other powers namely Russia France Serbia and Great Britain played a more significant role in causing the war than has been traditionally suggested.",
         "te",
         "True",
         "370",
         "Germany and Austria-Hungary",
         null
        ],
        [
         "46",
         "2019 వరకు బైబులును ఎన్ని భాషలలో అనువదించారు",
         "The Bible has been translated into many languages from the biblical languages of Hebrew Aramaic and Greek. the full Bible has been translated into 670 languages the New Testament has been translated into 1521 languages and Bible portions or stories into 1121 other languages. Thus at least some portion of the Bible has been translated into 3312 languages.",
         "te",
         "True",
         "148",
         "670",
         null
        ],
        [
         "47",
         "2011 భారత జనగణన గణాంకాల ప్రకారం గుంటూరు పట్టణ జనాభా ఎంత ",
         "Guntur  is a city within the Andhra Pradesh Capital Region. Located away from the state capital Amaravati Guntur city is the administrative headquarters of Guntur district of the Indian state of Andhra Pradesh. It is a municipal corporation and also the headquarters of Guntur mandal in Guntur revenue division. It is situated on the plains at a distance of to north of the Bay of Bengal. The city is the third most populous in the state with a population of 743654 and urban agglomeration population around one million as per 2011 census of India.",
         "te",
         "True",
         "464",
         "743,654",
         null
        ],
        [
         "48",
         "నీరు ఆవిరిగా మారడానికి ఎంత ఉష్ణోగ్రత కావాలి",
         "Water in Earth's atmosphere is not merely below its boiling point 100 °C but at altitude it goes below its freezing point 0 °C due to water's highly polar attraction. When combined with its quantity water vapor then has a relevant dew point and frost point unlike e. g. carbon dioxide and methane. Water vapor thus has a scale height a fraction of that of the bulk atmosphere as the water condenses and exits primarily in the troposphere the lowest layer of the atmosphere. Carbon dioxide  and methane being non-polar rise above water vapor. The absorption and emission of both compounds contribute to Earth's emission to space and thus the planetary greenhouse effect. This greenhouse forcing is directly observable via distinct spectral features versus water vapor and observed to be rising with rising levels. Conversely adding water vapor at high altitudes has a disproportionate impact which is why methane rising then oxidizing to and two water molecules and jet traffic have disproportionately high warming effects.",
         "te",
         "True",
         "67",
         "100 °C",
         null
        ],
        [
         "49",
         "టెలివిజన్ ను ఎవరు కనుగొన్నారు",
         "John Logie Baird  13 August 188814 June 1946 was a Scottish engineer innovator one of the inventors of the mechanical television demonstrating the first working television system on 26 January 1926 and inventor of both the first publicly demonstrated colour television system and the first purely electronic colour television picture tube.",
         "te",
         "True",
         "0",
         "John Logie Baird",
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3011
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>lang</th>\n",
       "      <th>answerable</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_inlang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది</td>\n",
       "      <td>Portland is the largest city in the U.S. state...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు</td>\n",
       "      <td>The word cholera is from \"kholera\" from χολή \"...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>Indian subcontinent</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు</td>\n",
       "      <td>Since it became widespread in the 19th century...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>451</td>\n",
       "      <td>England</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది</td>\n",
       "      <td>World War I occurred from 1914 to 1918. In ter...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>1914</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది</td>\n",
       "      <td>World War I often abbreviated as WWI or WW1 al...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>155</td>\n",
       "      <td>28 July 1914</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>2011 జనగణన ప్రకారం రెయ్యలగడ్ద గ్రామములో పురుషు...</td>\n",
       "      <td>Reyyalagadda is a village belonging to Gangara...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>378</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>2011 జనాభా లెక్కల ప్రకారం బూతుమిల్లిపాడు గ్రామ...</td>\n",
       "      <td>Boothumillipadu is a village in Gannavaram man...</td>\n",
       "      <td>te</td>\n",
       "      <td>True</td>\n",
       "      <td>308</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>2011 జనాభా లెక్కల ప్రకారం మల్లవేముల గ్రామ జనాభ...</td>\n",
       "      <td>Mallavemula is a village belonging to Chagalam...</td>\n",
       "      <td>te</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>1131</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>2011 నాటికి రష్యా దేశ ప్రధాన మంత్రి ఎవరు</td>\n",
       "      <td>Andria Urushadze  born April 25 1968 is a Geor...</td>\n",
       "      <td>te</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>వ్లాదిమిర్ పుతిన్</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>2011 భారత జనగణన గణాంకాల ప్రకారం గుంటూరు పట్టణ ...</td>\n",
       "      <td>Guntur district is 11391 sq. km. Spread over a...</td>\n",
       "      <td>te</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>743,654</td>\n",
       "      <td>743,654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3011 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0               ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది    \n",
       "1            కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు    \n",
       "2            కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు    \n",
       "3                మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది    \n",
       "4                మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది    \n",
       "...                                                 ...   \n",
       "3006  2011 జనగణన ప్రకారం రెయ్యలగడ్ద గ్రామములో పురుషు...   \n",
       "3007  2011 జనాభా లెక్కల ప్రకారం బూతుమిల్లిపాడు గ్రామ...   \n",
       "3008  2011 జనాభా లెక్కల ప్రకారం మల్లవేముల గ్రామ జనాభ...   \n",
       "3009           2011 నాటికి రష్యా దేశ ప్రధాన మంత్రి ఎవరు   \n",
       "3010  2011 భారత జనగణన గణాంకాల ప్రకారం గుంటూరు పట్టణ ...   \n",
       "\n",
       "                                                context lang  answerable  \\\n",
       "0     Portland is the largest city in the U.S. state...   te        True   \n",
       "1     The word cholera is from \"kholera\" from χολή \"...   te        True   \n",
       "2     Since it became widespread in the 19th century...   te        True   \n",
       "3     World War I occurred from 1914 to 1918. In ter...   te        True   \n",
       "4     World War I often abbreviated as WWI or WW1 al...   te        True   \n",
       "...                                                 ...  ...         ...   \n",
       "3006  Reyyalagadda is a village belonging to Gangara...   te        True   \n",
       "3007  Boothumillipadu is a village in Gannavaram man...   te        True   \n",
       "3008  Mallavemula is a village belonging to Chagalam...   te       False   \n",
       "3009  Andria Urushadze  born April 25 1968 is a Geor...   te       False   \n",
       "3010  Guntur district is 11391 sq. km. Spread over a...   te       False   \n",
       "\n",
       "      answer_start               answer      answer_inlang  \n",
       "0                0             Portland               None  \n",
       "1               99  Indian subcontinent               None  \n",
       "2              451              England               None  \n",
       "3               26                 1914               None  \n",
       "4              155         28 July 1914               None  \n",
       "...            ...                  ...                ...  \n",
       "3006           378                   37                 37  \n",
       "3007           308                  433                433  \n",
       "3008            -1                 1131               1131  \n",
       "3009            -1       Vladimir Putin  వ్లాదిమిర్ పుతిన్  \n",
       "3010            -1              743,654            743,654  \n",
       "\n",
       "[3011 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdebce29",
   "metadata": {},
   "source": [
    "## Week 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36d6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabicDf_train = df_train_clean[df_train_clean['lang'] == 'ar'].copy()\n",
    "teluguDf_train = df_train_clean[df_train_clean['lang'] == 'te'].copy()\n",
    "koreanDf_train = df_train_clean[df_train_clean['lang'] == 'ko'].copy()\n",
    "\n",
    "arabicDf_val = df_val_clean[df_val_clean['lang'] == 'ar'].copy()\n",
    "teluguDf_val = df_val_clean[df_val_clean['lang'] == 'te'].copy()\n",
    "koreanDf_val = df_val_clean[df_val_clean['lang'] == 'ko'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f1642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arabicDf_train = df_train[df_train['lang'] == 'ar']\n",
    "# teluguDf_train = df_train[df_train['lang'] == 'te']\n",
    "# koreanDf_train = df_train[df_train['lang'] == 'ko']\n",
    "\n",
    "# arabicDf_val = df_val[df_val['lang'] == 'ar']\n",
    "# teluguDf_val = df_val[df_val['lang'] == 'te']\n",
    "# koreanDf_val = df_val[df_val['lang'] == 'ko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074d9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability(question, unigram_fd, bigram_fd):\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    prob = 1.0\n",
    "    for bigram in bigrams:\n",
    "        bigram_count = bigram_fd[bigram]\n",
    "        unigram_count = unigram_fd[(bigram[0],)]\n",
    "        if unigram_count > 0 and bigram_count > 0:\n",
    "            prob *= bigram_count / unigram_count\n",
    "        else:\n",
    "            prob *= 1e-6\n",
    "    return prob\n",
    "\n",
    "def compute_logprob(question, unigram_fd, bigram_fd):\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    bigrams_list = list(ngrams(tokens, 2))\n",
    "    log_prob = 0.0\n",
    "    for bigram in bigrams_list:\n",
    "        bigram_count = bigram_fd[bigram]\n",
    "        unigram_count = unigram_fd[(bigram[0],)]\n",
    "        if unigram_count > 0 and bigram_count > 0:\n",
    "            prob = bigram_count / unigram_count\n",
    "        else:\n",
    "            prob = 1e-6  # smoothing for unseen bigrams\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)  # return log_prob and number of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22048f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_counts(corpus):\n",
    "    allUnigrams = []\n",
    "    allBigrams = []\n",
    "    allTrigrams = []\n",
    "\n",
    "    for text in corpus:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        allUnigrams.extend(tokens)\n",
    "        allBigrams.extend(list(ngrams(tokens, 2)))\n",
    "        allTrigrams.extend(list(ngrams(tokens, 3)))\n",
    "\n",
    "    unigram_fd = FreqDist(allUnigrams)\n",
    "    bigram_fd = FreqDist(allBigrams)\n",
    "    trigram_fd = FreqDist(allTrigrams)\n",
    "\n",
    "    return unigram_fd, bigram_fd, trigram_fd\n",
    "\n",
    "\n",
    "# build counts\n",
    "unigram_fd, bigram_fd, trigram_fd = build_counts(df_train_clean['context'])\n",
    "V = len(unigram_fd)\n",
    "\n",
    "def conditional_prob_unigram(w, unigram_fd):\n",
    "    return unigram_fd[w] / sum(unigram_fd.values())\n",
    "\n",
    "def conditional_prob_bigram(w2, w1, bigram_fd, unigram_fd, k=0.0):\n",
    "    # Add-k for bigram if you like, or simple MLE\n",
    "    bi = bigram_fd[(w1,w2)]\n",
    "    uni = unigram_fd[w1]\n",
    "    if uni>0:\n",
    "        return bi/uni\n",
    "    return 1.0/V\n",
    "\n",
    "def conditional_prob_trigram(w3, w1, w2, trigram_fd, bigram_fd, V, k=0.0):\n",
    "    tri = trigram_fd[(w1,w2,w3)]\n",
    "    bi  = bigram_fd[(w1,w2)]\n",
    "    if bi>0:\n",
    "        return (tri + k) / (bi + k*V)\n",
    "    return 1.0/V\n",
    "\n",
    "def sentence_logprob_interpolated(sentence, unigram_fd, bigram_fd, trigram_fd,\n",
    "                                  V, lambdas=(0.1,0.3,0.6), k=0.0):\n",
    "    # lambdas: (lambda_uni, lambda_bi, lambda_tri) must sum to 1\n",
    "    lam1, lam2, lam3 = lambdas\n",
    "    toks = nltk.word_tokenize(sentence)\n",
    "    trigs = list(ngrams(toks, 3))\n",
    "    logp = 0.0\n",
    "    for w1,w2,w3 in trigs:\n",
    "        p_uni = conditional_prob_unigram(w3, unigram_fd)\n",
    "        p_bi  = conditional_prob_bigram(w3, w2, bigram_fd, unigram_fd, k)\n",
    "        p_tri = conditional_prob_trigram(w3, w1, w2, trigram_fd, bigram_fd, V, k)\n",
    "        p = lam1*p_uni + lam2*p_bi + lam3*p_tri\n",
    "        logp += math.log(p)\n",
    "    return logp, len(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c0353",
   "metadata": {},
   "source": [
    "### Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b41a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAINING: unigram model ---\n",
    "allUnigrams_ar = []\n",
    "\n",
    "for q in arabicDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_ar.extend(tokens)\n",
    "\n",
    "unigram_fd_ar = FreqDist(allUnigrams_ar)\n",
    "total_tokens_train = sum(unigram_fd_ar.values())\n",
    "V = len(unigram_fd_ar)  # vocabulary size\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_en.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under unigram model ---\n",
    "def question_logprob_unigram(sentence, unigram_fd, total_tokens, V, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    log_prob = 0.0\n",
    "    for w in tokens:\n",
    "        count = unigram_fd[w]\n",
    "        if count > 0:\n",
    "            prob = count / total_tokens\n",
    "        else:\n",
    "            prob = smoothing  # unseen word → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_ar = 0.0\n",
    "total_tokens_ar = 0\n",
    "\n",
    "for q in arabicDf_val['question']:\n",
    "    logp, n = question_logprob_unigram(q, unigram_fd_ar, total_tokens_train, V)\n",
    "    total_log_prob_ar += logp\n",
    "    total_tokens_ar += n\n",
    "\n",
    "perplexity_uni_ar = math.exp(-total_log_prob_ar / total_tokens_ar)\n",
    "# print(\"Validation Perplexity (Unigram) for Arabic:\", perplexity_uni_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c83b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all bigrams in arabicDf questions\n",
    "allBigrams_ar = []\n",
    "allUnigrams_ar = []\n",
    "for q in arabicDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    unigrams = list(ngrams(tokens, 1))\n",
    "    allBigrams_ar.extend(bigrams)\n",
    "    allUnigrams_ar.extend(unigrams)\n",
    "\n",
    "unigram_fd_ar = FreqDist(allUnigrams_ar)\n",
    "bigram_fd_ar = FreqDist(allBigrams_ar)\n",
    "# print(unigram_fd_ar.most_common(10))\n",
    "# print(bigram_fd_ar.most_common(10))\n",
    "cfdist_ar = ConditionalFreqDist((bigram[0], bigram) for bigram in allBigrams_ar)\n",
    "# print(cfdist_ar['ما'].most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9639bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabicDf_val['question_prob'] = arabicDf_val['question'].apply(lambda q: compute_probability(q, unigram_fd_ar, bigram_fd_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9d131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total log probability and total tokens over validation set\n",
    "total_log_prob_ar = 0.0\n",
    "total_tokens_ar  = 0\n",
    "for q in arabicDf_val['question']:\n",
    "    logp, n = compute_logprob(q, unigram_fd_ar, bigram_fd_ar)\n",
    "    total_log_prob_ar += logp\n",
    "    total_tokens_ar += n\n",
    "\n",
    "# Perplexity\n",
    "perplexity_bi_ar = math.exp(-total_log_prob_ar / total_tokens_ar)\n",
    "# print(\"Validation Perplexity for Arabic:\", perplexity_bi_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "303df6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trigram model - Arabic\n",
    "\n",
    "# --- TRAINING: trigram + bigram + unigram ---\n",
    "allTrigrams_ar = []\n",
    "allBigrams_ar = []\n",
    "allUnigrams_ar = []\n",
    "\n",
    "for q in arabicDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_ar.extend(tokens)\n",
    "    allBigrams_ar.extend(list(ngrams(tokens, 2)))\n",
    "    allTrigrams_ar.extend(list(ngrams(tokens, 3)))\n",
    "\n",
    "unigram_fd_ar = FreqDist(allUnigrams_ar)\n",
    "bigram_fd_ar = FreqDist(allBigrams_ar)\n",
    "trigram_fd_ar = FreqDist(allTrigrams_ar)\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_ar.most_common(10)}\")\n",
    "# print(f\"Most common bigrams: {bigram_fd_ar.most_common(10)}\")\n",
    "# print(f\"Most common trigrams: {trigram_fd_ar.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under trigram model ---\n",
    "def question_logprob(sentence, bigram_fd, trigram_fd, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "    log_prob = 0.0\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        trigram_count = trigram_fd[(w1, w2, w3)]\n",
    "        bigram_count = bigram_fd[(w1, w2)]\n",
    "        if bigram_count > 0 and trigram_count > 0:\n",
    "            prob = trigram_count / bigram_count\n",
    "        else:\n",
    "            prob = smoothing  # unseen trigram → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_ar = 0.0\n",
    "total_tokens_ar = 0\n",
    "\n",
    "for q in arabicDf_val['question']:\n",
    "    logp, n = question_logprob(q, bigram_fd_ar, trigram_fd_ar)\n",
    "    total_log_prob_ar += logp\n",
    "    total_tokens_ar += n\n",
    "\n",
    "perplexity_tri_ar = math.exp(-total_log_prob_ar / total_tokens_ar)\n",
    "# print(\"Validation Perplexity (Trigram) for Arabic:\", perplexity_tri_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25137d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate perplexity on validation set with interpolation\n",
    "total_log, total_tokens = 0.0, 0\n",
    "for s in arabicDf_val['question']:\n",
    "    lp, n = sentence_logprob_interpolated(s, unigram_fd, bigram_fd, trigram_fd, V,\n",
    "                                          lambdas=(0.1,0.3,0.6), k=0.1)\n",
    "    total_log += lp\n",
    "    total_tokens += n\n",
    "perplexity_inter_ar = math.exp(-total_log/total_tokens)\n",
    "# print(\"Interpolated trigram perplexity for Arabic:\", perplexity_inter_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795ab77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity (Arabic): 3744.866432577014\n",
      "Bigram Perplexity (Arabic): 3475.076581820621\n",
      "Trigram Perplexity (Arabic): 3721.809419391342\n",
      "Interpolated Trigram Perplexity (Arabic): 378.3794847875941\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the different models\n",
    "print(f\"Unigram Perplexity (Arabic): {perplexity_uni_ar}\")\n",
    "print(f\"Bigram Perplexity (Arabic): {perplexity_bi_ar}\")\n",
    "print(f\"Trigram Perplexity (Arabic): {perplexity_tri_ar}\")\n",
    "print(f\"Interpolated Trigram Perplexity (Arabic): {perplexity_inter_ar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70294140",
   "metadata": {},
   "source": [
    "### Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac314be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAINING: unigram model ---\n",
    "allUnigrams_ko = []\n",
    "\n",
    "for q in koreanDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_ko.extend(tokens)\n",
    "\n",
    "unigram_fd_ko = FreqDist(allUnigrams_ko)\n",
    "total_tokens_train = sum(unigram_fd_ko.values())\n",
    "V = len(unigram_fd_ko)  # vocabulary size\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_en.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under unigram model ---\n",
    "def question_logprob_unigram(sentence, unigram_fd, total_tokens, V, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    log_prob = 0.0\n",
    "    for w in tokens:\n",
    "        count = unigram_fd[w]\n",
    "        if count > 0:\n",
    "            prob = count / total_tokens\n",
    "        else:\n",
    "            prob = smoothing  # unseen word → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_ko = 0.0\n",
    "total_tokens_ko = 0\n",
    "\n",
    "for q in koreanDf_val['question']:\n",
    "    logp, n = question_logprob_unigram(q, unigram_fd_ko, total_tokens_train, V)\n",
    "    total_log_prob_ko += logp\n",
    "    total_tokens_ko += n\n",
    "\n",
    "perplexity_uni_ko = math.exp(-total_log_prob_ko / total_tokens_ko)\n",
    "# print(\"Validation Perplexity (Unigram) for Korean:\", perplexity_uni_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2ad69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('가장',), 527), (('무엇인가',), 497), (('언제',), 336), (('몇',), 234), (('어디인가',), 228), (('큰',), 194), (('누구인가',), 186), (('세상에서',), 142), (('누구인가요',), 105), (('무엇인가요',), 95)]\n",
      "[(('가장', '큰'), 172), (('세상에서', '가장'), 138), (('가장', '많은'), 66), (('나라는', '어디인가'), 64), (('몇', '년도에'), 63), (('사람은', '누구인가'), 55), (('가장', '높은'), 48), (('몇', '개의'), 44), (('지도자는', '누구인가'), 37), (('얼마나', '되나요'), 34)]\n"
     ]
    }
   ],
   "source": [
    "# Make a list of all bigrams in arabicDf questions\n",
    "allBigrams_ko = []\n",
    "allUnigrams_ko = []\n",
    "for q in koreanDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    unigrams = list(ngrams(tokens, 1))\n",
    "    allBigrams_ko.extend(bigrams)\n",
    "    allUnigrams_ko.extend(unigrams)\n",
    "\n",
    "unigram_fd_ko = FreqDist(allUnigrams_ko)\n",
    "bigram_fd_ko = FreqDist(allBigrams_ko)\n",
    "print(unigram_fd_ko.most_common(10))\n",
    "print(bigram_fd_ko.most_common(10))\n",
    "cfdist_ko = ConditionalFreqDist((bigram[0], bigram) for bigram in allBigrams_ko)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22cb9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "koreanDf_val['question_prob'] = koreanDf_val['question'].apply(lambda q: compute_probability(q, unigram_fd_ko, bigram_fd_ko))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8347a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Perplexity for Korean: 1061.2832744231378\n"
     ]
    }
   ],
   "source": [
    "# Calculate total log probability and total tokens over validation set\n",
    "total_log_prob_ko = 0.0\n",
    "total_tokens_ko = 0\n",
    "for q in koreanDf_val['question']:\n",
    "    logp, n = compute_logprob(q, unigram_fd_ko, bigram_fd_ko)\n",
    "    total_log_prob_ko += logp\n",
    "    total_tokens_ko += n\n",
    "\n",
    "# Perplexity\n",
    "perplexity_bi_ko = math.exp(-total_log_prob_ko / total_tokens_ko)\n",
    "print(\"Validation Perplexity for Korean:\", perplexity_bi_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "353fb6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trigram model - Korean\n",
    "\n",
    "# --- TRAINING: trigram + bigram + unigram ---\n",
    "allTrigrams_ko = []\n",
    "allBigrams_ko = []\n",
    "allUnigrams_ko = []\n",
    "\n",
    "for q in koreanDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_ko.extend(tokens)\n",
    "    allBigrams_ko.extend(list(ngrams(tokens, 2)))\n",
    "    allTrigrams_ko.extend(list(ngrams(tokens, 3)))\n",
    "\n",
    "unigram_fd_ko = FreqDist(allUnigrams_ko)\n",
    "bigram_fd_ko = FreqDist(allBigrams_ko)\n",
    "trigram_fd_ko = FreqDist(allTrigrams_ko)\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_ko.most_common(10)}\")\n",
    "# print(f\"Most common bigrams: {bigram_fd_ko.most_common(10)}\")\n",
    "# print(f\"Most common trigrams: {trigram_fd_ko.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under trigram model ---\n",
    "def question_logprob(sentence, bigram_fd, trigram_fd, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "    log_prob = 0.0\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        trigram_count = trigram_fd[(w1, w2, w3)]\n",
    "        bigram_count = bigram_fd[(w1, w2)]\n",
    "        if bigram_count > 0 and trigram_count > 0:\n",
    "            prob = trigram_count / bigram_count\n",
    "        else:\n",
    "            prob = smoothing  # unseen trigram → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_ko = 0.0\n",
    "total_tokens_ko = 0\n",
    "\n",
    "for q in koreanDf_val['question']:\n",
    "    logp, n = question_logprob(q, bigram_fd_ko, trigram_fd_ko)\n",
    "    total_log_prob_ko += logp\n",
    "    total_tokens_ko += n\n",
    "\n",
    "perplexity_tri_ko = math.exp(-total_log_prob_ko / total_tokens_ko)\n",
    "# print(\"Validation Perplexity (Trigram) for Korean:\", perplexity_tri_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de11ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate perplexity on validation set with interpolation\n",
    "total_log, total_tokens = 0.0, 0\n",
    "for s in koreanDf_val['question']:\n",
    "    lp, n = sentence_logprob_interpolated(s, unigram_fd, bigram_fd, trigram_fd, V,\n",
    "                                          lambdas=(0.1,0.3,0.6), k=0.1)\n",
    "    total_log += lp\n",
    "    total_tokens += n\n",
    "perplexity_inter_ko = math.exp(-total_log/total_tokens)\n",
    "# print(\"Interpolated trigram perplexity for Telugu:\", perplexity_inter_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5822022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity (Korean): 4539.477360388252\n",
      "Bigram Perplexity (Korean): 1061.2832744231378\n",
      "Trigram Perplexity (Korean): 682.3894216748316\n",
      "Interpolated Trigram Perplexity (Korean): 148.2215742629018\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the different models\n",
    "print(f\"Unigram Perplexity (Korean): {perplexity_uni_ko}\")\n",
    "print(f\"Bigram Perplexity (Korean): {perplexity_bi_ko}\")\n",
    "print(f\"Trigram Perplexity (Korean): {perplexity_tri_ko}\")\n",
    "print(f\"Interpolated Trigram Perplexity (Korean): {perplexity_inter_ko}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec30748",
   "metadata": {},
   "source": [
    "### Telugu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78716265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAINING: unigram model ---\n",
    "allUnigrams_te = []\n",
    "\n",
    "for q in teluguDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_te.extend(tokens)\n",
    "\n",
    "unigram_fd_te = FreqDist(allUnigrams_te)\n",
    "total_tokens_train = sum(unigram_fd_te.values())\n",
    "V = len(unigram_fd_te)  # vocabulary size\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_en.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under unigram model ---\n",
    "def question_logprob_unigram(sentence, unigram_fd, total_tokens, V, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    log_prob = 0.0\n",
    "    for w in tokens:\n",
    "        count = unigram_fd[w]\n",
    "        if count > 0:\n",
    "            prob = count / total_tokens\n",
    "        else:\n",
    "            prob = smoothing  # unseen word → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_te = 0.0\n",
    "total_tokens_te = 0\n",
    "\n",
    "for q in teluguDf_val['question']:\n",
    "    logp, n = question_logprob_unigram(q, unigram_fd_te, total_tokens_train, V)\n",
    "    total_log_prob_te += logp\n",
    "    total_tokens_te += n\n",
    "\n",
    "perplexity_uni_te = math.exp(-total_log_prob_te / total_tokens_te)\n",
    "# print(\"Validation Perplexity (Unigram) for Telugu:\", perplexity_uni_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "debe16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all bigrams in arabicDf questions\n",
    "allBigrams_telugu = []\n",
    "allUnigrams_telugu = []\n",
    "for q in teluguDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    unigrams = list(ngrams(tokens, 1))\n",
    "    allBigrams_telugu.extend(bigrams)\n",
    "    allUnigrams_telugu.extend(unigrams)\n",
    "\n",
    "unigram_fd_te = FreqDist(allUnigrams_telugu)\n",
    "bigram_fd_te = FreqDist(allBigrams_telugu)\n",
    "# print(unigram_fd_te.most_common(10))\n",
    "# print(bigram_fd_te.most_common(10))\n",
    "cfdist_telugu = ConditionalFreqDist((bigram[0], bigram) for bigram in allBigrams_telugu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d2e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "teluguDf_val['question_prob'] = teluguDf_val['question'].apply(lambda q: compute_probability(q, unigram_fd_te, bigram_fd_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb3957d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total log probability and total tokens over validation set\n",
    "total_log_prob_te = 0.0\n",
    "total_tokens_te = 0\n",
    "for q in teluguDf_val['question']:\n",
    "    logp, n = compute_logprob(q, unigram_fd_te, bigram_fd_te)\n",
    "    total_log_prob_te += logp\n",
    "    total_tokens_te += n\n",
    "\n",
    "# Perplexity\n",
    "perplexity_bi_te = math.exp(-total_log_prob_te / total_tokens_te)\n",
    "# print(\"Validation Perplexity for Telugu:\", perplexity_bi_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7bc6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trigram model - Telugu\n",
    "\n",
    "# --- TRAINING: trigram + bigram + unigram ---\n",
    "allTrigrams_te = []\n",
    "allBigrams_te = []\n",
    "allUnigrams_te = []\n",
    "\n",
    "for q in teluguDf_train['question']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_te.extend(tokens)\n",
    "    allBigrams_te.extend(list(ngrams(tokens, 2)))\n",
    "    allTrigrams_te.extend(list(ngrams(tokens, 3)))\n",
    "\n",
    "unigram_fd_te = FreqDist(allUnigrams_te)\n",
    "bigram_fd_te = FreqDist(allBigrams_te)\n",
    "trigram_fd_te = FreqDist(allTrigrams_te)\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_te.most_common(10)}\")\n",
    "# print(f\"Most common bigrams: {bigram_fd_te.most_common(10)}\")\n",
    "# print(f\"Most common trigrams: {trigram_fd_te.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under trigram model ---\n",
    "def question_logprob(sentence, bigram_fd, trigram_fd, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "    log_prob = 0.0\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        trigram_count = trigram_fd[(w1, w2, w3)]\n",
    "        bigram_count = bigram_fd[(w1, w2)]\n",
    "        if bigram_count > 0 and trigram_count > 0:\n",
    "            prob = trigram_count / bigram_count\n",
    "        else:\n",
    "            prob = smoothing  # unseen trigram → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_te = 0.0\n",
    "total_tokens_te = 0\n",
    "\n",
    "for q in teluguDf_val['question']:\n",
    "    logp, n = question_logprob(q, bigram_fd_te, trigram_fd_te)\n",
    "    total_log_prob_te += logp\n",
    "    total_tokens_te += n\n",
    "\n",
    "perplexity_tri_te = math.exp(-total_log_prob_te / total_tokens_te)\n",
    "# print(\"Validation Perplexity (Trigram) for Telugu:\", perplexity_tri_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ab595f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate perplexity on validation set with interpolation\n",
    "total_log, total_tokens = 0.0, 0\n",
    "for s in teluguDf_val['question']:\n",
    "    lp, n = sentence_logprob_interpolated(s, unigram_fd, bigram_fd, trigram_fd, V,\n",
    "                                          lambdas=(0.1,0.3,0.6), k=0.1)\n",
    "    total_log += lp\n",
    "    total_tokens += n\n",
    "perplexity_inter_te = math.exp(-total_log/total_tokens)\n",
    "# print(\"Interpolated trigram perplexity for Telugu:\", perplexity_inter_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0261025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity (Telugu): 2567.776781647863\n",
      "Bigram Perplexity (Telugu): 540.9787802403338\n",
      "Trigram Perplexity (Telugu): 429.6502383147644\n",
      "Interpolated Trigram Perplexity (Telugu): 191.84511292710405\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the different models\n",
    "print(f\"Unigram Perplexity (Telugu): {perplexity_uni_te}\")\n",
    "print(f\"Bigram Perplexity (Telugu): {perplexity_bi_te}\")\n",
    "print(f\"Trigram Perplexity (Telugu): {perplexity_tri_te}\")\n",
    "print(f\"Interpolated Trigram Perplexity (Telugu): {perplexity_inter_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e920574",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07b5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAINING: unigram model ---\n",
    "allUnigrams_en = []\n",
    "\n",
    "for q in df_train['context']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_en.extend(tokens)\n",
    "\n",
    "unigram_fd_en = FreqDist(allUnigrams_en)\n",
    "total_tokens_train = sum(unigram_fd_en.values())\n",
    "V = len(unigram_fd_en)  # vocabulary size\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_en.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under unigram model ---\n",
    "def question_logprob_unigram(sentence, unigram_fd, total_tokens, V, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    log_prob = 0.0\n",
    "    for w in tokens:\n",
    "        count = unigram_fd[w]\n",
    "        if count > 0:\n",
    "            prob = count / total_tokens\n",
    "        else:\n",
    "            prob = smoothing  # unseen word → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_en = 0.0\n",
    "total_tokens_en = 0\n",
    "\n",
    "for q in df_val['context']:\n",
    "    logp, n = question_logprob_unigram(q, unigram_fd_en, total_tokens_train, V)\n",
    "    total_log_prob_en += logp\n",
    "    total_tokens_en += n\n",
    "\n",
    "perplexity_uni_en = math.exp(-total_log_prob_en / total_tokens_en)\n",
    "# print(\"Validation Perplexity (Unigram) for English:\", perplexity_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9195d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all bigrams in context\n",
    "allBigrams_en = []\n",
    "allUnigrams_en = []\n",
    "for q in df_train_clean['context']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    unigrams = list(ngrams(tokens, 1))\n",
    "    allBigrams_en.extend(bigrams)\n",
    "    allUnigrams_en.extend(unigrams)\n",
    "\n",
    "unigram_fd_en = FreqDist(allUnigrams_en)\n",
    "bigram_fd_en = FreqDist(allBigrams_en)\n",
    "# print(unigram_fd_en.most_common(10))\n",
    "# print(bigram_fd_en.most_common(10))\n",
    "cfdist_en = ConditionalFreqDist((bigram[0], bigram) for bigram in allBigrams_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b0507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['context_prob'] = df_val['context'].apply(lambda q: compute_probability(q, unigram_fd_en, bigram_fd_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96647554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total log probability and total tokens over validation set\n",
    "total_log_prob_en = 0.0\n",
    "total_tokens_en = 0\n",
    "for q in df_val['context']:\n",
    "    logp, n = compute_logprob(q, unigram_fd_en, bigram_fd_en)\n",
    "    total_log_prob_en += logp\n",
    "    total_tokens_en += n\n",
    "\n",
    "# Perplexity\n",
    "perplexity_bi_en = math.exp(-total_log_prob_en / total_tokens_en)\n",
    "# print(\"Validation Perplexity (Bigram) for English:\", perplexity_bi_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "780ca5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trigram model - English\n",
    "\n",
    "# --- TRAINING: trigram + bigram + unigram ---\n",
    "allTrigrams_en = []\n",
    "allBigrams_en = []\n",
    "allUnigrams_en = []\n",
    "\n",
    "for q in df_train['context']:\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    allUnigrams_en.extend(tokens)\n",
    "    allBigrams_en.extend(list(ngrams(tokens, 2)))\n",
    "    allTrigrams_en.extend(list(ngrams(tokens, 3)))\n",
    "\n",
    "unigram_fd_en = FreqDist(allUnigrams_en)\n",
    "bigram_fd_en = FreqDist(allBigrams_en)\n",
    "trigram_fd_en = FreqDist(allTrigrams_en)\n",
    "\n",
    "# print(f\"Most common unigrams: {unigram_fd_en.most_common(10)}\")\n",
    "# print(f\"Most common bigrams: {bigram_fd_en.most_common(10)}\")\n",
    "# print(f\"Most common trigrams: {trigram_fd_en.most_common(10)}\")\n",
    "\n",
    "# --- FUNCTION: log-probability of a sentence under trigram model ---\n",
    "def question_logprob(sentence, bigram_fd, trigram_fd, smoothing=1e-6):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "    log_prob = 0.0\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        trigram_count = trigram_fd[(w1, w2, w3)]\n",
    "        bigram_count = bigram_fd[(w1, w2)]\n",
    "        if bigram_count > 0 and trigram_count > 0:\n",
    "            prob = trigram_count / bigram_count\n",
    "        else:\n",
    "            prob = smoothing  # unseen trigram → small probability\n",
    "        log_prob += math.log(prob)\n",
    "    return log_prob, len(tokens)\n",
    "\n",
    "# --- VALIDATION: calculate perplexity ---\n",
    "total_log_prob_en = 0.0\n",
    "total_tokens_en = 0\n",
    "\n",
    "for q in df_val['context']:\n",
    "    logp, n = question_logprob(q, bigram_fd_en, trigram_fd_en)\n",
    "    total_log_prob_en += logp\n",
    "    total_tokens_en += n\n",
    "\n",
    "perplexity_tri_en = math.exp(-total_log_prob_en / total_tokens_en)\n",
    "# print(\"Validation Perplexity (Trigram) for English:\", perplexity_tri_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f236677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate perplexity on validation set with interpolation\n",
    "total_log, total_tokens = 0.0, 0\n",
    "for s in df_val['context']:\n",
    "    lp, n = sentence_logprob_interpolated(s, unigram_fd, bigram_fd, trigram_fd, V,\n",
    "                                          lambdas=(0.1,0.3,0.6), k=0.1)\n",
    "    total_log += lp\n",
    "    total_tokens += n\n",
    "perplexity_inter_en = math.exp(-total_log/total_tokens)\n",
    "# print(\"Interpolated trigram perplexity for English:\", perplexity_inter_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54b177ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity (English): 1991.2012701142155\n",
      "Bigram Perplexity (English): 1088.9448235837644\n",
      "Trigram Perplexity (English): 8453.467175831895\n",
      "Interpolated Trigram Perplexity (English): 720.8373580260715\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the different models\n",
    "print(f\"Unigram Perplexity (English): {perplexity_uni_en}\")\n",
    "print(f\"Bigram Perplexity (English): {perplexity_bi_en}\")\n",
    "print(f\"Trigram Perplexity (English): {perplexity_tri_en}\")\n",
    "print(f\"Interpolated Trigram Perplexity (English): {perplexity_inter_en}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
